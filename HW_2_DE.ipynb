{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19efae20",
      "metadata": {
        "id": "19efae20"
      },
      "source": [
        "**1. Смотрим на Hadoop Distributed File System**\n",
        "\n",
        "В рамках этой части вам нужно будет обращаться к HDFS с помощью CLI, разместить файлы для следующих заданий в распределеннй файловой системе и выполнить несколько преобразований над ними.\n",
        "\n",
        "Для работы файлы можно скачать по следующим ссылкам:\n",
        "- Логи посещения сайтов юзерами за некоторый промежуток времени [ссылка](https://drive.google.com/file/d/1WXyq5WVSWwJYXPuH4kyAJ5mrR3XgfO_H/view?usp=sharing)\n",
        "\n",
        "Разместите их в нашем внутреннем файловом хранилище с помощью HDFS CLI, для дальнейшего удобства под каждый файл стоит создать каталог с простым и понятным именем, разместить сами файлы в разных каталогах.\n",
        "\n",
        "Набор комманд, которые вам могут в этом помочь, доступны [здесь](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)\n",
        "\n",
        "В ячейках ниже должен быть полный набор комманд ваших обращей к консоли"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c0f990",
      "metadata": {
        "id": "b4c0f990",
        "outputId": "4b0cd4da-bd10-4619-ac02-cda922c3fd64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 items\r\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:40 /input\r\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:42 /output\r\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:34 /tmp\r\n"
          ]
        }
      ],
      "source": [
        "## вы можете обращаться к консоли из ноутбука таким способом\n",
        "!hdfs dfs -ls /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a5a267",
      "metadata": {
        "id": "41a5a267",
        "outputId": "33b4bc5e-9527-4241-a541-83ae98ce3891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 items\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:40 /input\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:42 /output\n",
            "drwxr-xr-x   - root supergroup          0 2024-06-01 07:34 /tmp\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "## или же использовать для этого меджик строчку в ячейке %%bash, как вам будет удобнее\n",
        "\n",
        "hdfs dfs -ls /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61786cf4",
      "metadata": {
        "id": "61786cf4",
        "outputId": "51760388-8777-4b84-c564-d28e769ba12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r--   1 root supergroup         24 2024-06-01 07:40 /input/input.txt\r\n"
          ]
        }
      ],
      "source": [
        "!hdfs dfs -ls -R -h /input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0c6e16b",
      "metadata": {
        "id": "a0c6e16b"
      },
      "outputs": [],
      "source": [
        "## ваше решение здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e1f83ac",
      "metadata": {
        "id": "1e1f83ac"
      },
      "source": [
        "**2. Решаем задачи MapReduce**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "990332ef",
      "metadata": {
        "id": "990332ef"
      },
      "source": [
        "**2.1 Подсчет слов в тексте**\n",
        "\n",
        "В рамках данного задания вам нужно подсчитать кол-во слов в тексте Библии (файл приложен к ДЗ в чате тг), то есть необходимо реализовать базовый функционал утилиты word count.\n",
        "\n",
        "**Важно** - подсчитывайте число только тех слов, длина которых больше 4 символов. Проводить процесс удаления знаков препинания и прочих символов **не нужно**\n",
        "\n",
        "Ниже вам представлены ячейки, в которых вы должны описать структуру маппера/редьсюера и ниже вызвать их в bash-скрипте запуска MR-таски"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "295c61fd",
      "metadata": {
        "id": "295c61fd"
      },
      "outputs": [],
      "source": [
        "%%writefile mapper.py\n",
        "## сюда вы пишете питоновский скрипт для работы маппера\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1bef060",
      "metadata": {
        "id": "c1bef060"
      },
      "outputs": [],
      "source": [
        "%%writefile reducer.py\n",
        "## сюда вы пишете питоновский скрипт для работы редьюсера\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b35cd9",
      "metadata": {
        "id": "97b35cd9"
      },
      "source": [
        "В качестве проверки ваших python-скриптов до запуска MR таски можно произвести их запуск через консольные команды\n",
        "\n",
        "Тогда наша задача не будет выполняться через датаноды, а только на локальной машине, но в случае ошибок в скриптах вы увидите их и сможете исправить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5975e36",
      "metadata": {
        "id": "a5975e36"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "## пример запуска скриптов на неймноде для проверки их работы\n",
        "\n",
        "cat file | python3 mapper.py | sort -k1,1 (с нужными ключами сортировки) | python3 reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8279f6c1",
      "metadata": {
        "id": "8279f6c1"
      },
      "source": [
        "Как только в данной проверке вы получите успешный и корректный результат, можете запустить Map Reduce в ячейке ниже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecb1749",
      "metadata": {
        "id": "1ecb1749"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "## шаблон для запуска MR таски\n",
        "\n",
        "# обязательная чистка директории, куда будем складывать результат отрабоки mr\n",
        "hdfs dfs -rm -r /word_count_task || true\n",
        "\n",
        "# запус mr таски с указанием пути до нужного jar\n",
        "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
        "    -D mapreduce.job.name=\"word-count\" \\\n",
        "    -files ./mapper.py,./reducer.py \\\n",
        "    -mapper \"python3 mapper.py\" \\\n",
        "    -reducer \"python3 reducer.py\" \\\n",
        "    -input ## тут указать путь до нужного файла в hdfs\n",
        "    -output /word_count_task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe9c0ff5",
      "metadata": {
        "id": "fe9c0ff5"
      },
      "source": [
        "Мониторить процесс работы таски можно на nodemanager по порту 8088 (уже прокинут в конфиге), там будет UI, в котором будет видно вашу запущенную задачу и её статус."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f62cdb6",
      "metadata": {
        "id": "4f62cdb6"
      },
      "source": [
        "Результат работы скрипта должен выглядеть следующим образом (вывод тестовый):\n",
        "\n",
        "```bash\n",
        "word count\n",
        "abtr 6852\n",
        "btoad 4237\n",
        "stress 1932\n",
        "zen 1885\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868c1f67",
      "metadata": {
        "id": "868c1f67"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "## запустите эту команду, чтобы вывести счетчик определенных слов, которые мы указали на grep\n",
        "## Это нам будет необходимо для визуального анализа результата работы вашего скрипта\n",
        "## в sort можете указать тот разделитель колонок, с которым у вас результат выплевывает редьюсер\n",
        "\n",
        "hdfs dfs -cat /word_count_task/* | grep  -E 'lord\\.|god\\.|pray\\.' | sort -t$'\\t' -k2.2nr  | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1511d296",
      "metadata": {
        "id": "1511d296"
      },
      "source": [
        "**2.2 Решаем задачу поиска самых посещаемых сайтов**\n",
        "\n",
        "В данном задании нужно поработать с логом данных о посещении юзерами различных сайтов.\n",
        "Формат данных: `url;временная метка`. Вам нужно вывести топ 5 сайтов по посещаемости в каждую из дат, которая представлена в наших данных.\n",
        "\n",
        "Результат работы скрипта должен выглядеть следующим образом:\n",
        "\n",
        "```bash\n",
        "date        site                            count\n",
        "2024-05-25  https://gonzales-bautista.com/  987\n",
        "2024-05-25  https://smith.com/              654\n",
        "2024-05-25  https://www.smith.com/          321\n",
        "```\n",
        "\n",
        "**Рекомендации**\n",
        "\n",
        "1. Вам могу пригодиться дополнительные параметры mr таски, отвечающие за настройку шаффла, и правил сортировки ключей внутри него. Почитать о примерах их использования можно [здесь](https://hadoop.apache.org/docs/current/hadoop-streaming/HadoopStreaming.html#More_Usage_Examples).\n",
        "\n",
        "2. Не рекомендуем использовать `\\t` в качестве символа разделителя для сложного ключа (потому что по дефолту таб используется для разделения колонок данных, и ключом в таком случае будет только первая колонка до таба). Если вы будете собирать сложный ключ для нужной вам сортировки данных, лучше всего будет использовать другие симловы, к примеру `+, =`.\n",
        "\n",
        "3. Возможно, у вас не получится решить данную задачу за одну mr таску, тогда вы просто описываете в решении скрипты ваших мапперов, редьюсеров под каждую из mr тасок, которые вам нужно запустить для получения нужного результата.\n",
        "\n",
        "**Важно** помнить, что любой маппер и редьюсер должен работать за O(1) памяти, и если вы будете создавать какой-то список, куда будете складывать какие-то данные, то он не должен быть размера O(n). Если такой момент в вашем решении будет, пожалуйста, поясните его текстово, что с вашими переменными все ок, и у них нет размера O(n)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfe909b",
      "metadata": {
        "id": "0cfe909b"
      },
      "outputs": [],
      "source": [
        "## ваше решение здесь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffeefcb",
      "metadata": {
        "id": "2ffeefcb"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "## запустите эту команду, чтобы вывести результат работы по определенным компаниям, которые мы указали на grep\n",
        "## Это нам будет необходимо для визуального анализа результата работы вашего скрипта\n",
        "## в sort можете указать тот разделитель колонок, с которым у вас результат выплевывает редьюсер\n",
        "## укажите путь до той директории на hdfs, куда вы складывали результат\n",
        "\n",
        "!hdfs dfs -cat /output/* | grep -E '2024-05-28|2024-06-02|2024-05-30' | column -t -s$'\\t'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
